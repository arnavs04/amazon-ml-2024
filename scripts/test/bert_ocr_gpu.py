# -*- coding: utf-8 -*-
"""amazon ml challenge

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/amazon-ml-challenge-f2dcd56a-cd09-4214-91bc-ecc29038d43f.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240914/auto/storage/goog4_request%26X-Goog-Date%3D20240914T062049Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0e392f2858a237bce9f87f7be5492a29c2a7976e1c5e5e94f37d5dd491a47b9d0519b83cb70604f73d59b26e76518ff37ae9761116dfbedcc2ff624767e47891743babd625e680c3a75903aaa61aba6bb446e3384d8c95cd08f55af292503caacb21c73d525ac29e538db9fcf5d1d935f510c277979aa8995fb109de5d524cfbd7f9a8d272b9dff15a76001c8e4677753ac3748f71c504402844e5f08ef870f53c4b914d31ffe547f64f5064534d6c6e90d4d60f5391e109d373d31be8dfbbac29e3ceb157f49947f77c1b30029c6be47f306f1f2d3b3c1ca272c01416627ac5539e5f8882cb0f9e4f741285a52f11928036808b0aed3a0d2d05643d491d9678
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'amazon-ml:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5693856%2F9384777%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240914%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240914T062049Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D753991505101a48b91fb0d720e130f1d805019609378d6a3c0a754b5c703b2f303d65488005caead3b17b39c9c0d0221792d8836663ca2a23c97f506b4a4291ae7496d18fe19e5676481e68689c04e9dd6fb4e8c8fcfde74aa1dd8e6a0df1ad4b050e643d4cc106f742d26322af826911eb6ce8b374994f2bd29671c3843f0bb7144ed69dc10b8095ce810419710c7055adf74e57296514a534c81a6685bd4743bca482704bf6db2c1a3e32c932fb2849c6a87b5732b7249e239943d01636bf0109ec9ed034c575e5469e3474d7af7e192a7a647dff2f863a08ce899dbeb8563eda5ff208428a7dcebf8f25c0f286c7495cda132f9efdab206dff6ce5a80bf02'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""# Directory"""

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""# Imports & Others"""

import os
import random
import warnings
import requests
# import multiprocessing
import re
import time
import urllib
from time import time as timer
from pathlib import Path
from io import BytesIO

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

import easyocr
# import pytesseract
# import cv2
from functools import partial

from PIL import Image
from tqdm import tqdm

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast
from torchvision import transforms

from transformers import BertTokenizer, BertModel


print("Libraries Imported!")

# Suppress specific warnings
warnings.filterwarnings('ignore')

# Check if CUDA (GPU) is available
if torch.cuda.is_available():
    # Get the number of available GPUs
    num_gpus = torch.cuda.device_count()

    # Loop through each GPU and print its name
    for i in range(num_gpus):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
else:
    print("No GPU available")

# # Check for GPU availability
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# print(f"Using device: {device}")

# Hyperparameters
BATCH_SIZE = 32
EPOCHS = 5
LEARNING_RATE = 1e-4
MAX_LEN = 128
NUM_WORKERS = 0

# Initialize EasyOCR Reader for text extraction
# Step 1: Set GPU 1 for EasyOCR
os.environ["CUDA_VISIBLE_DEVICES"] = "1"

# Step 2: Initialize EasyOCR, this will use GPU 1
reader = easyocr.Reader(['en'], gpu=True)
reader = easyocr.Reader(['en'], gpu=False)

entity_unit_map = {
    "width": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "depth": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "height": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "item_weight": {"milligram", "kilogram", "microgram", "gram", "ounce", "ton", "pound"},
    "maximum_weight_recommendation": {"milligram", "kilogram", "microgram", "gram", "ounce", "ton", "pound"},
    "voltage": {"millivolt", "kilovolt", "volt"},
    "wattage": {"kilowatt", "watt"},
    "item_volume": {"cubic foot", "microlitre", "cup", "fluid ounce", "centilitre", "imperial gallon", "pint", "decilitre", "litre", "millilitre", "quart", "cubic inch", "gallon"}
}

all_units = set.union(*entity_unit_map.values())
all_units.add("unknown")  # Add "unknown" as a possible unit

"""# EDA"""

train_data = pd.read_csv("/kaggle/input/amazon-ml/train.csv")
train_data.head()

train_data.info()

# Regular expression pattern to match: number, space, and unit
pattern = r'^\d+(\.\d+)?\s[a-zA-Z]+$'

# Filter rows that match the pattern
train_data_filtered = train_data[train_data['entity_value'].str.match(pattern)]

train_data_filtered.info()

# Regular expression pattern to extract the unit part
unit_pattern = r'\s+([a-zA-Z]+)$'

# Extract units from the filtered data
units = train_data_filtered['entity_value'].str.extract(unit_pattern)[0]

# Create a set of unique units
unique_units = set(units.dropna())
unique_units

# Regular expression pattern to extract the unit part
unit_pattern = r'\s+([a-zA-Z]+)$'

# Extract units from the 'entity_value' column
units = train_data_filtered['entity_value'].str.extract(unit_pattern)[0]

# Filter rows where the extracted unit is in the all_units set
train_data_filtered_2 = train_data_filtered[units.isin(all_units)]

# Output the filtered DataFrame
train_data_filtered_2.info()

# Extract units from the filtered data
units = train_data_filtered_2['entity_value'].str.extract(unit_pattern)[0]

# Create a set of unique units
unique_units = set(units.dropna())
unique_units

"""# Data Loading"""

def load_data():
    train_df = pd.read_csv('/kaggle/input/amazon-ml/train.csv')
    test_df = pd.read_csv('/kaggle/input/amazon-ml/test.csv')

    # Create a validation set
    train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

    return train_df, val_df, test_df

train_df, val_df, test_df = load_data()
train_df = train_data_filtered_2

# Initialize the LabelEncoder for units
unit_encoder = LabelEncoder()
unit_encoder.fit(list(all_units))

# Label encoding for entity_name
label_encoder = LabelEncoder()
label_encoder.fit(train_df['entity_name'])

class ProductImageDataset(Dataset):
    def __init__(self, df, tokenizer, max_len, is_test=False):
        self.df = df
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.is_test = is_test
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        if not is_test:
            self.df['encoded_entity_name'] = label_encoder.transform(self.df['entity_name'])

    def __len__(self):
        return len(self.df)

    def create_placeholder_image():
        return Image.new('RGB', (224, 224), color='black')

    def download_image(self, url):
        try:
            response = requests.get(url, timeout=10)
            img = Image.open(BytesIO(response.content)).convert('RGB')
            return img
        except Exception as e:
            print(f"Error downloading image: {e}")
            # Use the placeholder image if there is an error
            return self.create_placeholder_image()

    def __getitem__(self, idx):
        image_url = self.df.iloc[idx]['image_link']
        entity_name = self.df.iloc[idx]['entity_name']

        img = self.download_image(image_url)

        img = self.transform(img)

        try:
            # OCR Extraction using EasyOCR
            result = reader.readtext(np.array(img.permute(1, 2, 0)), detail=0)
            text = " ".join(result)
        except Exception as e:
            print(f"Error in OCR: {e}")
            text = ""

        # Concatenate entity_name with the OCR extracted text
        combined_text = f"{entity_name} {text}"

        # Tokenize text
        encoding = self.tokenizer.encode_plus(
            combined_text,
            add_special_tokens=True,
            max_length=self.max_len,
            padding='max_length',
            return_attention_mask=True,
            truncation=True,
            return_tensors='pt'
        )

        item = {
            'image': img,
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'text': combined_text,
            'entity_name': entity_name
        }

        if not self.is_test:
            item['entity_label'] = torch.tensor(self.df.iloc[idx]['encoded_entity_name'], dtype=torch.long)

            # Parse entity value and unit
            entity_value = self.df.iloc[idx]['entity_value']
            value, unit = self.parse_entity_value(entity_value)
            item['entity_value'] = torch.tensor(value, dtype=torch.float)

            # Handle empty unit string
            if unit == "":
                unit = "unknown"
            item['entity_unit'] = torch.tensor(unit_encoder.transform([unit])[0], dtype=torch.long)

        return item

    def parse_entity_value(self, entity_value):
        # Handle list-like strings
        if entity_value.startswith('[') and entity_value.endswith(']'):
            parts = entity_value[1:-1].split(',')
        else:
            parts = entity_value.split()

        # Extract numeric values
        values = []
        for part in parts:
            try:
                values.append(float(part.strip()))
            except ValueError:
                break

        # Calculate average if multiple values
        if values:
            value = sum(values) / len(values)
        else:
            value = 0.0

        # Extract unit
        unit = ' '.join(parts[len(values):]).strip()

#         print(f"Parsed: value = {value}, unit = {unit}")  # Debug print
        return value, unit

"""# Models"""

class EntityExtractionModel(nn.Module):
    def __init__(self, num_labels, num_units):
        super(EntityExtractionModel, self).__init__()
        self.num_labels = num_labels
        self.num_units = num_units
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.dropout = nn.Dropout(0.1)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)
        self.unit_classifier = nn.Linear(self.bert.config.hidden_size, num_units)

    def forward(self, input_ids, attention_mask, images):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output
        pooled_output = self.dropout(pooled_output)
        logits = self.classifier(pooled_output)
        value = self.regressor(pooled_output).squeeze(-1)
        unit_logits = self.unit_classifier(pooled_output)
        return logits, value, unit_logits

"""# Training & Inference Functions"""

def train_model(model, train_loader, val_loader, optimizer, classification_criterion, regression_criterion, unit_criterion, epochs):
    scaler = torch.amp.GradScaler('cuda')
    best_val_loss = float('inf')

    for epoch in tqdm(range(epochs), desc='Epoch'):
        model.train()
        total_loss = 0
        for batch in tqdm(train_loader, desc="Processing Training Batches"):
            optimizer.zero_grad()

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            labels = batch['entity_label'].to(device)
            values = batch['entity_value'].to(device)
            units = batch['entity_unit'].to(device)

            with autocast():
                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)
                classification_loss = classification_criterion(logits, labels)
                regression_loss = regression_criterion(predicted_values, values)
                unit_loss = unit_criterion(unit_logits, units)
                loss = classification_loss + regression_loss + unit_loss
                total_loss += loss.item()

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

        avg_train_loss = total_loss / len(train_loader)

        # Validation
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for batch in tqdm(val_loader, desc="Processing Valid Batches"):
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                images = batch['image'].to(device)
                labels = batch['entity_label'].to(device)
                values = batch['entity_value'].to(device)
                units = batch['entity_unit'].to(device)

                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)
                classification_loss = classification_criterion(logits, labels)
                regression_loss = regression_criterion(predicted_values, values)
                unit_loss = unit_criterion(unit_logits, units)
                loss = classification_loss + regression_loss + unit_loss
                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_loader)

        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), 'best_model.pth')
            print("Saved best model.")

def inference(model, test_loader, tokenizer):
    model.eval()
    predictions = []

    with torch.no_grad():
        for batch in test_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            entity_names = batch['entity_name']

            logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)

            # Get predicted entity names
            pred_entity_names = torch.argmax(logits, dim=1)
            pred_entity_names = label_encoder.inverse_transform(pred_entity_names.cpu().numpy())

            # Get predicted units
            pred_units = torch.argmax(unit_logits, dim=1)
            pred_units = unit_encoder.inverse_transform(pred_units.cpu().numpy())

            # Format predicted values
            for idx, (entity_name, value, unit) in enumerate(zip(entity_names, predicted_values.cpu().numpy(), pred_units)):
                formatted_value = format_value(value, unit, entity_name)
                predictions.append({
                    'index': batch['index'][idx] if 'index' in batch else idx,
                    'prediction': formatted_value
                })

    return pd.DataFrame(predictions)

"""# Helper Functions"""

entity_unit_map = {
    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},
    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},
    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},
    'item_weight': {'gram',
        'kilogram',
        'microgram',
        'milligram',
        'ounce',
        'pound',
        'ton'},
    'maximum_weight_recommendation': {'gram',
        'kilogram',
        'microgram',
        'milligram',
        'ounce',
        'pound',
        'ton'},
    'voltage': {'kilovolt', 'millivolt', 'volt'},
    'wattage': {'kilowatt', 'watt'},
    'item_volume': {'centilitre',
        'cubic foot',
        'cubic inch',
        'cup',
        'decilitre',
        'fluid ounce',
        'gallon',
        'imperial gallon',
        'litre',
        'microlitre',
        'millilitre',
        'pint',
        'quart'}
}

allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}

def common_mistake(unit):
    if unit in allowed_units:
        return unit
    if unit.replace('ter', 'tre') in allowed_units:
        return unit.replace('ter', 'tre')
    if unit.replace('feet', 'foot') in allowed_units:
        return unit.replace('feet', 'foot')
    return unit

def parse_string(s):
    s_stripped = "" if s==None or str(s)=='nan' else s.strip()
    if s_stripped == "":
        return None, None
    pattern = re.compile(r'^-?\d+(\.\d+)?\s+[a-zA-Z\s]+$')
    if not pattern.match(s_stripped):
        raise ValueError("Invalid format in {}".format(s))
    parts = s_stripped.split(maxsplit=1)
    number = float(parts[0])
    unit = common_mistake(parts[1])
    if unit not in allowed_units:
        raise ValueError("Invalid unit [{}] found in {}. Allowed units: {}".format(
            unit, s, allowed_units))
    return number, unit

def create_placeholder_image(image_save_path):
    try:
        placeholder_image = Image.new('RGB', (100, 100), color='black')
        placeholder_image.save(image_save_path)
    except Exception as e:
        return

def download_image(image_link, save_folder, retries=3, delay=3):
    if not isinstance(image_link, str):
        return

    filename = Path(image_link).name
    image_save_path = os.path.join(save_folder, filename)

    if os.path.exists(image_save_path):
        return

    for _ in range(retries):
        try:
            urllib.request.urlretrieve(image_link, image_save_path)
            return
        except:
            time.sleep(delay)

    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images

def download_images(image_links, download_folder, allow_multiprocessing=True):
    if not os.path.exists(download_folder):
        os.makedirs(download_folder)

    if allow_multiprocessing:
        download_image_partial = partial(
            download_image, save_folder=download_folder, retries=3, delay=3)

        with multiprocessing.Pool(64) as pool:
            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))
            pool.close()
            pool.join()
    else:
        for image_link in tqdm(image_links, total=len(image_links)):
            download_image(image_link, save_folder=download_folder, retries=3, delay=3)

def format_value(value, unit, entity_name):
    if entity_name not in entity_unit_map or unit not in entity_unit_map[entity_name]:
        return ""
    return f"{value:.2f} {unit}".strip()

"""# Main

*putting it all together*
"""

# Step 1: Set device to GPU 2
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

def main():
    # Initialize tokenizer
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

    # Create datasets and dataloaders
    train_dataset = ProductImageDataset(train_df, tokenizer, MAX_LEN)
    val_dataset = ProductImageDataset(val_df, tokenizer, MAX_LEN)
    test_dataset = ProductImageDataset(test_df, tokenizer, MAX_LEN, is_test=True)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

    # Initialize model
    num_labels = len(label_encoder.classes_)
    num_units = len(set.union(*entity_unit_map.values()))
    model = EntityExtractionModel(num_labels=num_labels, num_units=num_units).to(device)

    # Initialize optimizer and loss functions
    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
    classification_criterion = nn.CrossEntropyLoss()
    regression_criterion = nn.MSELoss()
    unit_criterion = nn.CrossEntropyLoss()

    # Train the model
    train_model(model, train_loader, val_loader, optimizer, classification_criterion, regression_criterion, unit_criterion, EPOCHS)

    # Load best model for inference
    model.load_state_dict(torch.load('best_model.pth'))

    # Perform inference on test set
    predictions_df = inference(model, test_loader, tokenizer)
    predictions_df.to_csv('output.csv', index=False)
    print("Predictions saved to output.csv")

main()

import os
import random
import warnings
import requests
import multiprocessing
import re
from io import BytesIO

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

from PIL import Image
import easyocr
from tqdm import tqdm

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from torchvision import transforms, models

from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup

print("Libraries Imported!")

warnings.filterwarnings('ignore')

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
BATCH_SIZE = 32
EPOCHS = 10
LEARNING_RATE = 2e-5
MAX_LEN = 128
NUM_WORKERS = multiprocessing.cpu_count()

# Initialize EasyOCR Reader for text extraction
reader = easyocr.Reader(['en'], gpu=True)

entity_unit_map = {
    "width": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "depth": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "height": {"centimetre", "foot", "millimetre", "metre", "inch", "yard"},
    "item_weight": {"milligram", "kilogram", "microgram", "gram", "ounce", "ton", "pound"},
    "maximum_weight_recommendation": {"milligram", "kilogram", "microgram", "gram", "ounce", "ton", "pound"},
    "voltage": {"millivolt", "kilovolt", "volt"},
    "wattage": {"kilowatt", "watt"},
    "item_volume": {"cubic foot", "microlitre", "cup", "fluid ounce", "centilitre", "imperial gallon", "pint", "decilitre", "litre", "millilitre", "quart", "cubic inch", "gallon"}
}

all_units = set.union(*entity_unit_map.values())
all_units.add("unknown")

def load_data():
    train_df = pd.read_csv('/kaggle/input/amazon-ml/train.csv')
    test_df = pd.read_csv('/kaggle/input/amazon-ml/test.csv')

    train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)

    return train_df, val_df, test_df

train_df, val_df, test_df = load_data()
train_df = train_data_filtered_2

unit_encoder = LabelEncoder()
unit_encoder.fit(list(all_units))

label_encoder = LabelEncoder()
label_encoder.fit(train_df['entity_name'])

class ProductImageDataset(Dataset):
    def __init__(self, df, tokenizer, max_len, is_test=False):
        self.df = df
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.is_test = is_test
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        if not is_test:
            self.df['encoded_entity_name'] = label_encoder.transform(self.df['entity_name'])

    def __len__(self):
        return len(self.df)

    @staticmethod
    def create_placeholder_image():
        return Image.new('RGB', (224, 224), color='black')

    def download_image(self, url):
        try:
            response = requests.get(url, timeout=10)
            img = Image.open(BytesIO(response.content)).convert('RGB')
            return img
        except Exception as e:
            print(f"Error downloading image: {e}")
            return self.create_placeholder_image()

    def __getitem__(self, idx):
        image_url = self.df.iloc[idx]['image_link']
        entity_name = self.df.iloc[idx]['entity_name']

        img = self.download_image(image_url)
        img = self.transform(img)

        try:
            result = reader.readtext(np.array(img.permute(1, 2, 0).cpu()), detail=0)
            text = " ".join(result)
        except Exception as e:
            print(f"Error in OCR: {e}")
            text = ""

        combined_text = f"{entity_name} {text}"

        encoding = self.tokenizer.encode_plus(
            combined_text,
            add_special_tokens=True,
            max_length=self.max_len,
            padding='max_length',
            return_attention_mask=True,
            truncation=True,
            return_tensors='pt'
        )

        item = {
            'image': img,
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'text': combined_text,
            'entity_name': entity_name
        }

        if not self.is_test:
            item['entity_label'] = torch.tensor(self.df.iloc[idx]['encoded_entity_name'], dtype=torch.long)

            entity_value = self.df.iloc[idx]['entity_value']
            value, unit = self.parse_entity_value(entity_value)
            item['entity_value'] = torch.tensor(value, dtype=torch.float)

            if unit == "":
                unit = "unknown"
            item['entity_unit'] = torch.tensor(unit_encoder.transform([unit])[0], dtype=torch.long)

        return item

    def parse_entity_value(self, entity_value):
        if entity_value.startswith('[') and entity_value.endswith(']'):
            parts = entity_value[1:-1].split(',')
        else:
            parts = entity_value.split()

        values = []
        for part in parts:
            try:
                values.append(float(part.strip()))
            except ValueError:
                break

        if values:
            value = sum(values) / len(values)
        else:
            value = 0.0

        unit = ' '.join(parts[len(values):]).strip()

        return value, unit

class EntityExtractionModel(nn.Module):
    def __init__(self, num_labels, num_units):
        super(EntityExtractionModel, self).__init__()
        self.num_labels = num_labels
        self.num_units = num_units
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.cnn = models.resnet50(pretrained=True)
        self.cnn.fc = nn.Identity()

        self.dropout = nn.Dropout(0.3)
        self.classifier = nn.Linear(self.bert.config.hidden_size + 2048, num_labels)
        self.regressor = nn.Linear(self.bert.config.hidden_size + 2048, 1)
        self.unit_classifier = nn.Linear(self.bert.config.hidden_size + 2048, num_units)

    def forward(self, input_ids, attention_mask, images):
        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        bert_pooled = bert_output.pooler_output

        cnn_features = self.cnn(images)

        combined_features = torch.cat((bert_pooled, cnn_features), dim=1)
        combined_features = self.dropout(combined_features)

        logits = self.classifier(combined_features)
        value = self.regressor(combined_features).squeeze(-1)
        unit_logits = self.unit_classifier(combined_features)

        return logits, value, unit_logits

def train_model(model, train_loader, val_loader, optimizer, scheduler, classification_criterion, regression_criterion, unit_criterion, epochs):
    scaler = GradScaler()
    best_val_loss = float('inf')

    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            optimizer.zero_grad()

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            labels = batch['entity_label'].to(device)
            values = batch['entity_value'].to(device)
            units = batch['entity_unit'].to(device)

            with autocast():
                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)
                classification_loss = classification_criterion(logits, labels)
                regression_loss = regression_criterion(predicted_values, values)
                unit_loss = unit_criterion(unit_logits, units)
                loss = classification_loss + regression_loss + unit_loss

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            scheduler.step()

            total_loss += loss.item()

        avg_train_loss = total_loss / len(train_loader)

        val_loss = validate_model(model, val_loader, classification_criterion, regression_criterion, unit_criterion)

        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}')

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), 'best_model.pth')
            print("Saved best model.")

def validate_model(model, val_loader, classification_criterion, regression_criterion, unit_criterion):
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            labels = batch['entity_label'].to(device)
            values = batch['entity_value'].to(device)
            units = batch['entity_unit'].to(device)

            with autocast():
                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)
                classification_loss = classification_criterion(logits, labels)
                regression_loss = regression_criterion(predicted_values, values)
                unit_loss = unit_criterion(unit_logits, units)
                loss = classification_loss + regression_loss + unit_loss
            val_loss += loss.item()

    return val_loss / len(val_loader)

def inference(model, test_loader, tokenizer):
    model.eval()
    predictions = []

    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Inference"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            images = batch['image'].to(device)
            entity_names = batch['entity_name']

            with autocast():
                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)

            pred_entity_names = torch.argmax(logits, dim=1)
            pred_entity_names = label_encoder.inverse_transform(pred_entity_names.cpu().numpy())

            pred_units = torch.argmax(unit_logits, dim=1)
            pred_units = unit_encoder.inverse_transform(pred_units.cpu().numpy())

            for idx, (entity_name, value, unit) in enumerate(zip(entity_names, predicted_values.cpu().numpy(), pred_units)):
                formatted_value = format_value(value, unit, entity_name)
                predictions.append({
                    'index': idx,
                    'prediction': formatted_value
                })

    return pd.DataFrame(predictions)

def format_value(value, unit, entity_name):
    if entity_name not in entity_unit_map or unit not in entity_unit_map[entity_name]:
        return ""
    return f"{value:.2f} {unit}".strip()

def main():
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

    train_dataset = ProductImageDataset(train_df, tokenizer, MAX_LEN)
    val_dataset = ProductImageDataset(val_df, tokenizer, MAX_LEN)
    test_dataset = ProductImageDataset(test_df, tokenizer, MAX_LEN, is_test=True)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)

    num_labels = len(label_encoder.classes_)
    num_units = len(unit_encoder.classes_)
    model = EntityExtractionModel(num_labels=num_labels, num_units=num_units).to(device)

    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)
    total_steps = len(train_loader) * EPOCHS
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

    classification_criterion = nn.CrossEntropyLoss()
    regression_criterion = nn.MSELoss()
    unit_criterion = nn.CrossEntropyLoss()

    train_model(model, train_loader, val_loader, optimizer, scheduler, classification_criterion, regression_criterion, unit_criterion, EPOCHS)

    model.load_state_dict(torch.load('best_model.pth'))

    predictions_df = inference(model, test_loader, tokenizer)
    predictions_df.to_csv('output.csv', index=False)
    print("Predictions saved to output.csv")

if __name__ == '__main__':
    main()

