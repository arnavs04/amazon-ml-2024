{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9384777,"sourceType":"datasetVersion","datasetId":5693856}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-14T10:16:27.825410Z","iopub.execute_input":"2024-09-14T10:16:27.826357Z","iopub.status.idle":"2024-09-14T10:16:28.243434Z","shell.execute_reply.started":"2024-09-14T10:16:27.826314Z","shell.execute_reply":"2024-09-14T10:16:28.242484Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-ml/sample_test.csv\n/kaggle/input/amazon-ml/sample_test_out_fail.csv\n/kaggle/input/amazon-ml/sample_test_out.csv\n/kaggle/input/amazon-ml/train.csv\n/kaggle/input/amazon-ml/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport warnings\nimport requests\nfrom io import BytesIO\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torchvision import models\n\nfrom transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n\nprint(\"Libraries Imported!\")\n\nwarnings.filterwarnings('ignore')\ntorch.backends.cudnn.benchmark = True\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Hyperparameters\nBATCH_SIZE = 16\nEPOCHS = 10\nLEARNING_RATE = 2e-5\nMAX_LEN = 128\nIMAGE_SIZE = 224\n\nentity_unit_map = {\n    \"width\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n    \"depth\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n    \"height\": {\"centimetre\", \"foot\", \"millimetre\", \"metre\", \"inch\", \"yard\"},\n    \"item_weight\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n    \"maximum_weight_recommendation\": {\"milligram\", \"kilogram\", \"microgram\", \"gram\", \"ounce\", \"ton\", \"pound\"},\n    \"voltage\": {\"millivolt\", \"kilovolt\", \"volt\"},\n    \"wattage\": {\"kilowatt\", \"watt\"},\n    \"item_volume\": {\"cubic foot\", \"microlitre\", \"cup\", \"fluid ounce\", \"centilitre\", \"imperial gallon\", \"pint\", \"decilitre\", \"litre\", \"millilitre\", \"quart\", \"cubic inch\", \"gallon\"}\n}\n\nall_units = set.union(*entity_unit_map.values())\nall_units.add(\"unknown\")\n\nunit_encoder = LabelEncoder()\nunit_encoder.fit(list(all_units))\n\nlabel_encoder = LabelEncoder()\n\nclass ProductImageDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len, is_test=False):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.is_test = is_test\n        self.transform = A.Compose([\n            A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n            ToTensorV2()\n        ])\n        if not is_test:\n            self.df['encoded_entity_name'] = label_encoder.transform(self.df['entity_name'])\n\n    def __len__(self):\n        return len(self.df)\n\n    @staticmethod\n    def download_image(url):\n        try:\n            response = requests.get(url, timeout=5)\n            img = Image.open(BytesIO(response.content)).convert('RGB')\n            return np.array(img)\n        except:\n            return np.zeros((IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.uint8)\n\n    def __getitem__(self, idx):\n        image_url = self.df.iloc[idx]['image_link']\n        entity_name = self.df.iloc[idx]['entity_name']\n        \n        img = self.download_image(image_url)\n        img = self.transform(image=img)['image']\n\n        combined_text = f\"{entity_name}\"\n\n        encoding = self.tokenizer.encode_plus(\n            combined_text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_attention_mask=True,\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        item = {\n            'image': img,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'entity_name': entity_name\n        }\n\n        if not self.is_test:\n            item['entity_label'] = torch.tensor(self.df.iloc[idx]['encoded_entity_name'], dtype=torch.long)\n            \n            entity_value = self.df.iloc[idx]['entity_value']\n            value, unit = self.parse_entity_value(entity_value)\n            item['entity_value'] = torch.tensor(value, dtype=torch.float)\n            \n            if unit == \"\":\n                unit = \"unknown\"\n            item['entity_unit'] = torch.tensor(unit_encoder.transform([unit])[0], dtype=torch.long)\n\n        return item\n\n    @staticmethod\n    def parse_entity_value(entity_value):\n        parts = entity_value.replace('[', '').replace(']', '').split()\n        values = [float(part) for part in parts if part.replace('.', '').isdigit()]\n        value = sum(values) / len(values) if values else 0.0\n        unit = ' '.join(parts[len(values):]).strip()\n        return value, unit\n\nclass EntityExtractionModel(nn.Module):\n    def __init__(self, num_labels, num_units):\n        super(EntityExtractionModel, self).__init__()\n        self.num_labels = num_labels\n        self.num_units = num_units\n        self.bert = AutoModel.from_pretrained('microsoft/deberta-v3-small')\n        self.cnn = models.efficientnet_b0(pretrained=True)\n        self.cnn.classifier = nn.Identity()\n        \n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(self.bert.config.hidden_size + 1280, 512)\n        self.classifier = nn.Linear(512, num_labels)\n        self.regressor = nn.Linear(512, 1)\n        self.unit_classifier = nn.Linear(512, num_units)\n\n    def forward(self, input_ids, attention_mask, images):\n        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        bert_pooled = bert_output.last_hidden_state[:, 0, :]\n        \n        cnn_features = self.cnn(images)\n        \n        combined_features = torch.cat((bert_pooled, cnn_features), dim=1)\n        x = self.dropout(combined_features)\n        x = F.relu(self.fc(x))\n        x = self.dropout(x)\n        \n        logits = self.classifier(x)\n        value = self.regressor(x).squeeze(-1)\n        unit_logits = self.unit_classifier(x)\n        \n        return logits, value, unit_logits\n\ndef train_model(model, train_loader, val_loader, optimizer, scheduler, classification_criterion, regression_criterion, unit_criterion, epochs):\n    scaler = GradScaler()\n    best_val_loss = float('inf')\n    \n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            optimizer.zero_grad(set_to_none=True)\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            images = batch['image'].to(device)\n            labels = batch['entity_label'].to(device)\n            values = batch['entity_value'].to(device)\n            units = batch['entity_unit'].to(device)\n\n            with autocast():\n                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n                classification_loss = classification_criterion(logits, labels)\n                regression_loss = regression_criterion(predicted_values, values)\n                unit_loss = unit_criterion(unit_logits, units)\n                loss = classification_loss + regression_loss + unit_loss\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        \n        val_loss = validate_model(model, val_loader, classification_criterion, regression_criterion, unit_criterion)\n        \n        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}')\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(\"Saved best model.\")\n\ndef validate_model(model, val_loader, classification_criterion, regression_criterion, unit_criterion):\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            images = batch['image'].to(device)\n            labels = batch['entity_label'].to(device)\n            values = batch['entity_value'].to(device)\n            units = batch['entity_unit'].to(device)\n\n            with autocast():\n                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n                classification_loss = classification_criterion(logits, labels)\n                regression_loss = regression_criterion(predicted_values, values)\n                unit_loss = unit_criterion(unit_logits, units)\n                loss = classification_loss + regression_loss + unit_loss\n            val_loss += loss.item()\n\n    return val_loss / len(val_loader)\n\ndef inference(model, test_loader, tokenizer):\n    model.eval()\n    predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Inference\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            images = batch['image'].to(device)\n            entity_names = batch['entity_name']\n\n            with autocast():\n                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n            \n            pred_entity_names = torch.argmax(logits, dim=1)\n            pred_entity_names = label_encoder.inverse_transform(pred_entity_names.cpu().numpy())\n            \n            pred_units = torch.argmax(unit_logits, dim=1)\n            pred_units = unit_encoder.inverse_transform(pred_units.cpu().numpy())\n            \n            for idx, (entity_name, value, unit) in enumerate(zip(entity_names, predicted_values.cpu().numpy(), pred_units)):\n                formatted_value = format_value(value, unit, entity_name)\n                predictions.append({\n                    'index': idx,\n                    'prediction': formatted_value\n                })\n\n    return pd.DataFrame(predictions)\n\ndef format_value(value, unit, entity_name):\n    if entity_name not in entity_unit_map or unit not in entity_unit_map[entity_name]:\n        return \"\"\n    return f\"{value:.2f} {unit}\".strip()\n\ndef main():\n    tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small')\n    \n    train_df = pd.read_csv('/kaggle/input/amazon-ml/train.csv')\n    test_df = pd.read_csv('/kaggle/input/amazon-ml/test.csv')\n    \n    train_df = train_df.head(5000)\n    # Regular expression pattern to match: number, space, and unit\n    pattern = r'^\\d+(\\.\\d+)?\\s[a-zA-Z]+$'\n\n    # Filter rows that match the pattern\n    train_data_filtered = train_df[train_df['entity_value'].str.match(pattern)]\n    # Regular expression pattern to extract the unit part\n    unit_pattern = r'\\s+([a-zA-Z]+)$'\n\n    # Extract units from the 'entity_value' column\n    units = train_data_filtered['entity_value'].str.extract(unit_pattern)[0]\n\n    # Filter rows where the extracted unit is in the all_units set\n    train_data_filtered_2 = train_data_filtered[units.isin(all_units)]\n    \n    train_df, val_df = train_test_split(train_data_filtered_2, test_size=0.1, random_state=42)\n    \n    label_encoder.fit(train_df['entity_name'])\n\n    print(\"Preparing datasets...\")\n    train_dataset = ProductImageDataset(train_df, tokenizer, MAX_LEN)\n    val_dataset = ProductImageDataset(val_df, tokenizer, MAX_LEN)\n    test_dataset = ProductImageDataset(test_df, tokenizer, MAX_LEN, is_test=True)\n\n    print(\"Creating data loaders...\")\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0 ,pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,pin_memory=True)\n\n    num_labels = len(label_encoder.classes_)\n    num_units = len(unit_encoder.classes_)\n    model = EntityExtractionModel(num_labels=num_labels, num_units=num_units).to(device)\n\n    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n    total_steps = len(train_loader) * EPOCHS\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n    \n    classification_criterion = nn.CrossEntropyLoss()\n    regression_criterion = nn.MSELoss()\n    unit_criterion = nn.CrossEntropyLoss()\n\n    print(\"Starting training...\")\n    train_model(model, train_loader, val_loader, optimizer, scheduler, classification_criterion, regression_criterion, unit_criterion, EPOCHS)\n\n    print(\"Loading best model for inference...\")\n    model.load_state_dict(torch.load('best_model.pth'))\n\n    print(\"Running inference on test set...\")\n    predictions_df = inference(model, test_loader, tokenizer)\n    predictions_df.to_csv('submission.csv', index=False)\n    print(\"Predictions saved to submission.csv\")\n\nif __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T10:16:28.245346Z","iopub.execute_input":"2024-09-14T10:16:28.245751Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"Libraries Imported!\nUsing device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c5df2958934e7e9a5bb8ff2ebfcb30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a1e19915ae34540aa22e8b0cfb8ffc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc29b5dad2e1460d9537b58a315f233c"}},"metadata":{}},{"name":"stdout","text":"Preparing datasets...\nCreating data loaders...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d7374b85d4e437c82e27b6e67e7427f"}},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|██████████| 20.5M/20.5M [00:00<00:00, 147MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 270/270 [07:27<00:00,  1.66s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Train Loss: 18363979542522044.0000, Val Loss: 1417956.5785\nSaved best model.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10:   7%|▋         | 19/270 [00:32<07:27,  1.78s/it]","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom torch.cuda.amp import autocast\nimport random\n\n# Assuming these constants and objects are available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef format_value(value, unit, entity_name):\n    \"\"\"Format the predicted value based on unit and entity_name.\"\"\"\n    if entity_name not in entity_unit_map or unit not in entity_unit_map[entity_name]:\n        return \"\"\n    return f\"{value:.2f} {unit}\".strip()\n\ndef predictor(image_link, category_id, entity_name):\n    '''\n    A simple random predictor. Replace this with actual model predictions.\n    '''\n    # For testing purposes, we'll generate random predictions.\n    # Replace this with actual inference logic.\n    if random.random() > 0.5:\n        return f\"{random.uniform(1, 100):.2f} inch\"\n    return \"\"\n\ndef inference(model, test_loader, tokenizer):\n    \"\"\"This function handles the model inference on test data.\"\"\"\n    model.eval()\n    predictions = []\n\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Inference\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            images = batch['image'].to(device)\n            entity_names = batch['entity_name']\n\n            with autocast():\n                logits, predicted_values, unit_logits = model(input_ids=input_ids, attention_mask=attention_mask, images=images)\n\n            # Convert the logits to meaningful values (labels and units)\n            pred_entity_names = torch.argmax(logits, dim=1)\n            pred_entity_names = label_encoder.inverse_transform(pred_entity_names.cpu().numpy())\n\n            pred_units = torch.argmax(unit_logits, dim=1)\n            pred_units = unit_encoder.inverse_transform(pred_units.cpu().numpy())\n\n            for idx, (entity_name, value, unit) in enumerate(zip(entity_names, predicted_values.cpu().numpy(), pred_units)):\n                formatted_value = format_value(value, unit, entity_name)\n                predictions.append({\n                    'index': idx,\n                    'prediction': formatted_value\n                })\n\n    return pd.DataFrame(predictions)\n\ndef run_test_prediction():\n    \"\"\"Run the prediction and save to submission.csv\"\"\"\n    DATASET_FOLDER = '/kaggle/input/amazon-ml'  # Path to your dataset folder\n    WORKING_DIR = '/kaggle/working/'\n    \n    # Step 1: Load test data\n    test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n    \n    # Step 2: Apply predictor function on test data\n    test['prediction'] = test.apply(\n        lambda row: predictor(row['image_link'], row['group_id'], row['entity_name']), axis=1)\n\n    # Step 3: Ensure predictions are formatted correctly\n    test['prediction'] = test['prediction'].apply(\n        lambda x: x if isinstance(x, str) and x else \"\")\n\n    # Step 4: Save the predictions to submission.csv\n    output_filename = os.path.join(WORKING_DIR, 'submission.csv')\n    test[['index', 'prediction']].to_csv(output_filename, index=False)\n\n    print(f\"Submission saved to {output_filename}\")\n\n\nrun_test_prediction()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}