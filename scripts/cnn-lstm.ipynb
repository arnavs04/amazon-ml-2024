{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9398471,"sourceType":"datasetVersion","datasetId":5693856},{"sourceId":9399301,"sourceType":"datasetVersion","datasetId":5705244},{"sourceId":9403424,"sourceType":"datasetVersion","datasetId":5708645}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport re\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nfrom pathlib import Path\nfrom functools import partial\nimport urllib\nimport multiprocessing\nimport argparse\nimport logging\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Constants\nentity_unit_map = {\n    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n    'voltage': {'kilovolt', 'millivolt', 'volt'},\n    'wattage': {'kilowatt', 'watt'},\n    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n}\n\nallowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n\n# Utility Functions\ndef common_mistake(unit):\n    if unit in allowed_units:\n        return unit\n    if unit.replace('ter', 'tre') in allowed_units:\n        return unit.replace('ter', 'tre')\n    if unit.replace('feet', 'foot') in allowed_units:\n        return unit.replace('feet', 'foot')\n    return unit\n\ndef parse_string(s):\n    s_stripped = \"\" if s is None or str(s) == 'nan' else s.strip()\n    if s_stripped == \"\":\n        return None, None\n    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n    if not pattern.match(s_stripped):\n        raise ValueError(\"Invalid format in {}\".format(s))\n    parts = s_stripped.split(maxsplit=1)\n    number = float(parts[0])\n    unit = common_mistake(parts[1])\n    if unit not in allowed_units:\n        raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n            unit, s, allowed_units))\n    return number, unit\n\ndef create_placeholder_image(image_save_path):\n    try:\n        placeholder_image = Image.new('RGB', (100, 100), color='black')\n        placeholder_image.save(image_save_path)\n    except Exception as e:\n        return\n\ndef download_image(image_link, save_folder, retries=3, delay=3):\n    if not isinstance(image_link, str):\n        return\n\n    filename = Path(image_link).name\n    image_save_path = os.path.join(save_folder, filename)\n\n    if os.path.exists(image_save_path):\n        return\n\n    for _ in range(retries):\n        try:\n            urllib.request.urlretrieve(image_link, image_save_path)\n            return\n        except:\n            time.sleep(delay)\n    \n    create_placeholder_image(image_save_path)\n\ndef download_images(image_links, download_folder, allow_multiprocessing=True):\n    if not os.path.exists(download_folder):\n        os.makedirs(download_folder)\n\n    if allow_multiprocessing:\n        download_image_partial = partial(\n            download_image, save_folder=download_folder, retries=3, delay=3)\n\n        with multiprocessing.Pool(64) as pool:\n            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links), desc=\"Downloading images\"))\n            pool.close()\n            pool.join()\n    else:\n        for image_link in tqdm(image_links, total=len(image_links), desc=\"Downloading images\"):\n            download_image(image_link, save_folder=download_folder, retries=3, delay=3)\n\ndef check_file(filename):\n    if not filename.lower().endswith('.csv'):\n        raise ValueError(\"Only CSV files are allowed.\")\n    if not os.path.exists(filename):\n        raise FileNotFoundError(\"Filepath: {} invalid or not found.\".format(filename))\n\ndef sanity_check(test_filename, output_filename):\n    check_file(test_filename)\n    check_file(output_filename)\n    \n    try:\n        test_df = pd.read_csv(test_filename)\n        output_df = pd.read_csv(output_filename)\n    except Exception as e:\n        raise ValueError(f\"Error reading the CSV files: {e}\")\n    \n    if 'index' not in test_df.columns:\n        raise ValueError(\"Test CSV file must contain the 'index' column.\")\n    \n    if 'index' not in output_df.columns or 'prediction' not in output_df.columns:\n        raise ValueError(\"Output CSV file must contain 'index' and 'prediction' columns.\")\n    \n    missing_index = set(test_df['index']).difference(set(output_df['index']))\n    if len(missing_index) != 0:\n        logger.warning(\"Missing index in test file: {}\".format(missing_index))\n        \n    extra_index = set(output_df['index']).difference(set(test_df['index']))\n    if len(extra_index) != 0:\n        logger.warning(\"Extra index in test file: {}\".format(extra_index))\n        \n    output_df.apply(lambda x: parse_string(x['prediction']), axis=1)\n    logger.info(\"Parsing successful for file: {}\".format(output_filename))\n\n# Data Preparation\ndef download_dataset_images():\n    train_df = pd.read_csv('/kaggle/input/amazon-ml-cleaned/train_clean.csv')\n    test_df = pd.read_csv('/kaggle/input/amazon-ml/test.csv')\n\n    os.makedirs('/kaggle/working/train', exist_ok=True)\n    os.makedirs('/kaggle/working/test', exist_ok=True)\n\n    logger.info(\"Downloading training images...\")\n    for index, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"Downloading training images\"):\n        image_url = row['image_link']\n        image_filename = f\"/kaggle/working/train/{index}.jpg\"\n        download_images([image_url], '/kaggle/working/train')\n        logger.debug(f\"Downloaded training image {index}\")\n\n    logger.info(\"Downloading test images...\")\n    for index, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Downloading test images\"):\n        image_url = row['image_link']\n        image_filename = f\"/kaggle/working/test/{index}.jpg\"\n        download_images([image_url], '/kaggle/working/test')\n        logger.debug(f\"Downloaded test image {index}\")\n\n    logger.info(\"Data preparation complete!\")\n\n# Image Preprocessing\ndef preprocess_image(image_path, target_size=(224, 224)):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, target_size)\n    img = img.astype(np.float32) / 255.0\n    return img\n\ndef preprocess_dataset(image_dir, output_dir, target_size=(224, 224)):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for filename in tqdm(os.listdir(image_dir), desc=f\"Preprocessing images in {image_dir}\"):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):\n            input_path = os.path.join(image_dir, filename)\n            output_path = os.path.join(output_dir, filename)\n            \n            preprocessed_img = preprocess_image(input_path, target_size)\n            cv2.imwrite(output_path, cv2.cvtColor((preprocessed_img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n\n# Label Preprocessing\ndef preprocess_labels(df):\n    def extract_value_and_unit(entity_value):\n        match = re.match(r'(\\d+(?:\\.\\d+)?)\\s*(\\w+)', str(entity_value))\n        if match:\n            value, unit = match.groups()\n            return float(value), unit.lower()\n        return None, None\n\n    def normalize_unit(unit, entity_name):\n        allowed_units = entity_unit_map.get(entity_name, [])\n        if unit in allowed_units:\n            return unit\n        return None\n\n    logger.info(\"Preprocessing labels...\")\n    df['value'], df['unit'] = zip(*df['entity_value'].map(extract_value_and_unit))\n    df['normalized_unit'] = df.apply(lambda row: normalize_unit(row['unit'], row['entity_name']), axis=1)\n    df = df.dropna(subset=['normalized_unit'])\n    \n    return df\n\n# Feature Extraction\ndef extract_cnn_features(image_path):\n    model = models.resnet50(pretrained=True)\n    model = torch.nn.Sequential(*list(model.children())[:-1])\n    model.eval()\n\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n\n    img = Image.open(image_path).convert('RGB')\n    img_tensor = transform(img).unsqueeze(0)\n    \n    with torch.no_grad():\n        features = model(img_tensor)\n    \n    return features.squeeze().numpy()\n\ndef extract_cnn_features_batch(image_dir):\n    cnn_features = {}\n    \n    for filename in tqdm(os.listdir(image_dir), desc=f\"Extracting CNN features from {image_dir}\"):\n        if filename.endswith(('.jpg', '.jpeg', '.png')):\n            image_path = os.path.join(image_dir, filename)\n            image_id = os.path.splitext(filename)[0]\n            \n            features = extract_cnn_features(image_path)\n            cnn_features[image_id] = features\n    \n    return cnn_features\n\n# Model Definition\nclass ProductDataset(Dataset):\n    def __init__(self, ocr_features, cnn_features, labels):\n        self.ocr_features = ocr_features\n        self.cnn_features = cnn_features\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return {\n            'ocr': self.ocr_features[idx],\n            'cnn': self.cnn_features[idx],\n            'label': self.labels[idx]\n        }\n\nclass HybridModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, cnn_feature_dim, num_classes):\n        super(HybridModel, self).__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        \n        self.fc_cnn = nn.Linear(cnn_feature_dim, hidden_dim)\n        \n        self.fc_combined = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, num_classes)\n        )\n    \n    def forward(self, ocr, cnn):\n        ocr_emb = self.embedding(ocr)\n        ocr_out, _ = self.lstm(ocr_emb)\n        ocr_out = ocr_out[:, -1, :]\n        \n        cnn_out = self.fc_cnn(cnn)\n        \n        combined = torch.cat((ocr_out, cnn_out), dim=1)\n        output = self.fc_combined(combined)\n        \n        return output\n\n# Training Function\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n            optimizer.zero_grad()\n            outputs = model(batch['ocr'], batch['cnn'])\n            loss = criterion(outputs, batch['label'])\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_total += batch['label'].size(0)\n            train_correct += predicted.eq(batch['label']).sum().item()\n        \n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}/{num_epochs}\"):\n                outputs = model(batch['ocr'], batch['cnn'])\n                loss = criterion(outputs, batch['label'])\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_total += batch['label'].size(0)\n                val_correct += predicted.eq(batch['label']).sum().item()\n        \n        logger.info(f'Epoch {epoch+1}/{num_epochs}, '\n              f'Train Loss: {train_loss/len(train_loader):.4f}, '\n              f'Train Accuracy: {100.*train_correct/train_total:.2f}%, '\n              f'Val Loss: {val_loss/len(val_loader):.4f}, '\n              f'Val Accuracy: {100.*val_correct/val_total:.2f}%')\n\n# Prediction Function\ndef make_predictions(model, test_loader, le):\n    predictions = []\n    model.eval()\n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Making predictions\"):\n            outputs = model(batch['ocr'], batch['cnn'])\n            _, predicted = outputs.max(1)\n            predictions.extend(predicted.cpu().numpy())\n    \n    return le.inverse_transform(predictions)\n\n# Error Analysis\ndef perform_error_analysis(val_data, val_predictions):\n    logger.info(\"Performing error analysis...\")\n    print(classification_report(val_data['true_label'], val_predictions['predicted_label']))\n\n    cm = confusion_matrix(val_data['true_label'], val_predictions['predicted_label'])\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.savefig('confusion_matrix.png')\n    plt.close()\n\n    errors = val_data[val_data['true_label'] != val_predictions['predicted_label']]\n    print(\"Example Errors:\")\n    for _, row in errors.head().iterrows():\n        print(f\"True: {row['true_label']}, Predicted: {row['predicted_label']}, Image: {row['image_link']}\")\n\n    error_by_entity = errors['entity_name'].value_counts(normalize=True)\n    plt.figure(figsize=(10, 6))\n    error_by_entity.plot(kind='bar')\n    plt.title('Error Distribution by Entity Type')\n    plt.ylabel('Error Rate')\n    plt.xlabel('Entity Type')\n    plt.savefig('error_distribution.png')\n    plt.close()\n\n    print(\"Error analysis complete. Check 'confusion_matrix.png' and 'error_distribution.png' for visualizations.\")\n\n# Main execution\ndownload_dataset_images()\n\n# Image Preprocessing\npreprocess_dataset('/kaggle/working/train', '/kaggle/working/preprocessed/train')\npreprocess_dataset('/kaggle/working/test', '/kaggle/working/preprocessed/test')\nprint(\"Image preprocessing complete!\")\n\n# Label Preprocessing\ntrain_df = pd.read_csv('/kaggle/input/amazon-ml-cleaned/train_clean.csv')\npreprocessed_train_df = preprocess_labels(train_df)\npreprocessed_train_df.to_csv('/kaggle/working/preprocessed/train_labels.csv', index=False)\nprint(\"Label preprocessing complete!\")\n\n# Feature Extraction\ntrain_cnn_features = extract_cnn_features_batch('preprocessed/train')\ntest_cnn_features = extract_cnn_features_batch('preprocessed/test')\npd.DataFrame.from_dict(train_cnn_features, orient='index').to_csv('features/train_cnn_features.csv')\npd.DataFrame.from_dict(test_cnn_features, orient='index').to_csv('features/test_cnn_features.csv')\nprint(\"CNN feature extraction complete!\")\n\n# Load features and labels\ntrain_ocr = pd.read_csv('features/train_ocr_features.csv', index_col=0)\ntrain_cnn = pd.read_csv('features/train_cnn_features.csv', index_col=0)\ntrain_labels = pd.read_csv('preprocessed/train_labels.csv')\n\n# Prepare data\nle = LabelEncoder()\ntrain_labels['encoded_value'] = le.fit_transform(train_labels['value'])\n\n# Split data\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    pd.concat([train_ocr, train_cnn], axis=1),\n    train_labels['encoded_value'],\n    test_size=0.2,\n    random_state=42\n)\n\n# Create datasets and dataloaders\ntrain_dataset = ProductDataset(train_data['ocr_text'].values, train_data.drop('ocr_text', axis=1).values, train_labels.values)\nval_dataset = ProductDataset(val_data['ocr_text'].values, val_data.drop('ocr_text', axis=1).values, val_labels.values)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\n\n# Initialize model\nvocab_size = 10000  # Adjust based on your vocabulary\nembedding_dim = 100\nhidden_dim = 128\ncnn_feature_dim = train_cnn.shape[1]\nnum_classes = len(le.classes_)\n\nmodel = HybridModel(vocab_size, embedding_dim, hidden_dim, cnn_feature_dim, num_classes)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\n# Train the model\ntrain_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')\nprint(\"Model training complete and saved!\")\n\n# Make predictions on test set\ntest_ocr = pd.read_csv('features/test_ocr_features.csv', index_col=0)\ntest_cnn = pd.read_csv('features/test_cnn_features.csv', index_col=0)\ntest_data = pd.concat([test_ocr, test_cnn], axis=1)\noriginal_test = pd.read_csv('dataset/test.csv')\n\ntest_dataset = ProductDataset(test_data['ocr_text'].values, test_data.drop('ocr_text', axis=1).values, np.zeros(len(test_data)))\ntest_loader = DataLoader(test_dataset, batch_size=32)\n\npredicted_values = make_predictions(model, test_loader, le)\n\n# Post-process predictions\ndef format_prediction(value, entity_name):\n    allowed_units = ALLOWED_UNITS.get(entity_name, [])\n    if not allowed_units:\n        return \"\"\n    unit = allowed_units[0]\n    return f\"{value:.2f} {unit}\"\n\n# Generate output dataframe\noutput_df = pd.DataFrame({\n    'index': original_test['index'],\n    'prediction': [format_prediction(value, entity_name) \n                   for value, entity_name in zip(predicted_values, original_test['entity_name'])]\n})\n\n# Save the output file\noutput_file = 'test_out.csv'\noutput_df.to_csv(output_file, index=False)\nprint(f\"Output file '{output_file}' generated.\")\n\n# Run sanity check\nprint(\"Running sanity check...\")\nrun_sanity_check(output_file)\nprint(\"Sanity check complete.\")\n\n# Perform error analysis (assuming you have validation data and predictions)\nval_data = pd.read_csv('validation_data.csv')\nval_predictions = pd.read_csv('validation_predictions.csv')\nperform_error_analysis(val_data, val_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}